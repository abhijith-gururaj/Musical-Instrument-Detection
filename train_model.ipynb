{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Dense, Conv2D, \\\n",
    "        MaxPooling2D, GlobalMaxPooling2D, Dropout, LeakyReLU, ZeroPadding2D\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set if batch normalization is needed for training the CNN\n",
    "batch_normalization = True\n",
    "epochs = 40\n",
    "\n",
    "def create_model(batch_norm):\n",
    "    \"\"\"Creates the CNN model\n",
    "\n",
    "    Args:\n",
    "        batch_norm (bool): decides whether to batch normalize the conv layers\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): CNN model\n",
    "    \"\"\"\n",
    "    # If batch normalization, bias can be ignored\n",
    "    use_bias=True\n",
    "    if batch_norm:\n",
    "        use_bias=False\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv layer 1: 3x3 convolution layer and 32 filters,\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), input_shape=(128, 43, 1),\n",
    "        data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv layer 1: 3x3 convolution layer and 32 filters,\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), data_format=\"channels_last\"))\n",
    "\n",
    "    # dropout\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Conv Layer 3: 3x3 convolution layer and 64 filters,\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv layer 4: 3x3 convolution layer and 64 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), data_format=\"channels_last\"))\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Conv layer 5: 3x3 convolution layer and 128 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format = 'channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv layer 6: 3x3 convolution layer and 128 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), data_format=\"channels_last\"))\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Conv layer 7: 3x3 convolution layer and 256 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv block 8: 3x3 convolution layer and 256 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Global max-pool layer\n",
    "    model.add(GlobalMaxPooling2D(data_format=\"channels_last\"))\n",
    "\n",
    "    # Dense layer\n",
    "    model.add(Dense(1024, use_bias=use_bias))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = Adam(0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,  X_train, X_val, y_train, y_val, epochs=20):\n",
    "    \"\"\"Train the CNN model\n",
    "    \"\"\"\n",
    "    tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                                      write_graph=True, write_images=False)\n",
    "    checkpoint = ModelCheckpoint('model.h5', \n",
    "            verbose=1, monitor='val_loss',save_best_only=True, mode='auto') \n",
    "    callbacks = [tensorboard, checkpoint]\n",
    "    \n",
    "    history = model.fit(x=X_train, y=y_train, batch_size=128, epochs=epochs,\n",
    "            validation_data=(X_val, y_val), callbacks=callbacks, shuffle=True)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 975. 1332. 1098. 1566. 1968. 1785. 1869. 1593. 1485. 1458. 1968.]\n",
      "[189. 183. 255. 345. 312. 261. 294. 285. 246. 282. 366.]\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d_16 (ZeroPad  (None, 130, 45, 1)        0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 130, 45, 32)       320       \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 130, 45, 32)       0         \n",
      "                                                                 \n",
      " zero_padding2d_17 (ZeroPad  (None, 132, 47, 32)       0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 132, 47, 32)       9248      \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 132, 47, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 44, 15, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 44, 15, 32)        0         \n",
      "                                                                 \n",
      " zero_padding2d_18 (ZeroPad  (None, 46, 17, 32)        0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 46, 17, 64)        18496     \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 46, 17, 64)        0         \n",
      "                                                                 \n",
      " zero_padding2d_19 (ZeroPad  (None, 48, 19, 64)        0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 48, 19, 64)        36928     \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 48, 19, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 16, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 16, 6, 64)         0         \n",
      "                                                                 \n",
      " zero_padding2d_20 (ZeroPad  (None, 18, 8, 64)         0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 18, 8, 128)        73856     \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 18, 8, 128)        0         \n",
      "                                                                 \n",
      " zero_padding2d_21 (ZeroPad  (None, 20, 10, 128)       0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 20, 10, 128)       147584    \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 20, 10, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPoolin  (None, 6, 3, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 6, 3, 128)         0         \n",
      "                                                                 \n",
      " zero_padding2d_22 (ZeroPad  (None, 8, 5, 128)         0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 5, 256)         295168    \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 8, 5, 256)         0         \n",
      "                                                                 \n",
      " zero_padding2d_23 (ZeroPad  (None, 10, 7, 256)        0         \n",
      " ding2D)                                                         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 10, 7, 256)        590080    \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 10, 7, 256)        0         \n",
      "                                                                 \n",
      " global_max_pooling2d_2 (Gl  (None, 256)               0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 11)                11275     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1446123 (5.52 MB)\n",
      "Trainable params: 1446123 (5.52 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 02:38:34.587179: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_2/dropout_8/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/134 [============================>.] - ETA: 0s - loss: 2.2619 - accuracy: 0.1773\n",
      "Epoch 1: val_loss improved from inf to 2.13855, saving model to model.h5\n",
      "134/134 [==============================] - 8s 47ms/step - loss: 2.2611 - accuracy: 0.1777 - val_loss: 2.1385 - val_accuracy: 0.2154\n",
      "Epoch 2/40\n",
      "  3/134 [..............................] - ETA: 5s - loss: 2.0667 - accuracy: 0.2865"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijith/anaconda3/envs/vt/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/134 [============================>.] - ETA: 0s - loss: 1.8350 - accuracy: 0.3729\n",
      "Epoch 2: val_loss improved from 2.13855 to 1.62124, saving model to model.h5\n",
      "134/134 [==============================] - 6s 44ms/step - loss: 1.8349 - accuracy: 0.3729 - val_loss: 1.6212 - val_accuracy: 0.4430\n",
      "Epoch 3/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.5669 - accuracy: 0.4707\n",
      "Epoch 3: val_loss improved from 1.62124 to 1.53702, saving model to model.h5\n",
      "134/134 [==============================] - 7s 49ms/step - loss: 1.5671 - accuracy: 0.4708 - val_loss: 1.5370 - val_accuracy: 0.4957\n",
      "Epoch 4/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4118 - accuracy: 0.5269\n",
      "Epoch 4: val_loss improved from 1.53702 to 1.42369, saving model to model.h5\n",
      "134/134 [==============================] - 7s 52ms/step - loss: 1.4118 - accuracy: 0.5269 - val_loss: 1.4237 - val_accuracy: 0.5242\n",
      "Epoch 5/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.2761 - accuracy: 0.5752\n",
      "Epoch 5: val_loss improved from 1.42369 to 1.27564, saving model to model.h5\n",
      "134/134 [==============================] - 8s 57ms/step - loss: 1.2759 - accuracy: 0.5753 - val_loss: 1.2756 - val_accuracy: 0.5808\n",
      "Epoch 6/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.1668 - accuracy: 0.6121\n",
      "Epoch 6: val_loss improved from 1.27564 to 1.18052, saving model to model.h5\n",
      "134/134 [==============================] - 8s 62ms/step - loss: 1.1670 - accuracy: 0.6125 - val_loss: 1.1805 - val_accuracy: 0.6083\n",
      "Epoch 7/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0840 - accuracy: 0.6389\n",
      "Epoch 7: val_loss did not improve from 1.18052\n",
      "134/134 [==============================] - 9s 66ms/step - loss: 1.0839 - accuracy: 0.6389 - val_loss: 1.2779 - val_accuracy: 0.6011\n",
      "Epoch 8/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.0299 - accuracy: 0.6575\n",
      "Epoch 8: val_loss improved from 1.18052 to 1.10352, saving model to model.h5\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 1.0293 - accuracy: 0.6577 - val_loss: 1.1035 - val_accuracy: 0.6471\n",
      "Epoch 9/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.9510 - accuracy: 0.6833\n",
      "Epoch 9: val_loss improved from 1.10352 to 1.08712, saving model to model.h5\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.9501 - accuracy: 0.6839 - val_loss: 1.0871 - val_accuracy: 0.6584\n",
      "Epoch 10/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.9135 - accuracy: 0.6924\n",
      "Epoch 10: val_loss did not improve from 1.08712\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.9129 - accuracy: 0.6926 - val_loss: 1.1164 - val_accuracy: 0.6448\n",
      "Epoch 11/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8911 - accuracy: 0.7060\n",
      "Epoch 11: val_loss did not improve from 1.08712\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.8907 - accuracy: 0.7061 - val_loss: 1.1067 - val_accuracy: 0.6405\n",
      "Epoch 12/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.8197 - accuracy: 0.7244\n",
      "Epoch 12: val_loss improved from 1.08712 to 1.07963, saving model to model.h5\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.8197 - accuracy: 0.7247 - val_loss: 1.0796 - val_accuracy: 0.6610\n",
      "Epoch 13/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7937 - accuracy: 0.7344\n",
      "Epoch 13: val_loss improved from 1.07963 to 1.06904, saving model to model.h5\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.7945 - accuracy: 0.7339 - val_loss: 1.0690 - val_accuracy: 0.6759\n",
      "Epoch 14/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7443 - accuracy: 0.7513\n",
      "Epoch 14: val_loss did not improve from 1.06904\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.7436 - accuracy: 0.7515 - val_loss: 1.0917 - val_accuracy: 0.6793\n",
      "Epoch 15/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.7267 - accuracy: 0.7531\n",
      "Epoch 15: val_loss improved from 1.06904 to 1.04348, saving model to model.h5\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.7272 - accuracy: 0.7531 - val_loss: 1.0435 - val_accuracy: 0.6723\n",
      "Epoch 16/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.7714\n",
      "Epoch 16: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.6806 - accuracy: 0.7714 - val_loss: 1.0444 - val_accuracy: 0.6849\n",
      "Epoch 17/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.6553 - accuracy: 0.7812\n",
      "Epoch 17: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.6543 - accuracy: 0.7815 - val_loss: 1.0679 - val_accuracy: 0.6882\n",
      "Epoch 18/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.7915\n",
      "Epoch 18: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.6232 - accuracy: 0.7912 - val_loss: 1.1227 - val_accuracy: 0.6653\n",
      "Epoch 19/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5949 - accuracy: 0.8034\n",
      "Epoch 19: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.5946 - accuracy: 0.8035 - val_loss: 1.0457 - val_accuracy: 0.7064\n",
      "Epoch 20/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5947 - accuracy: 0.8002\n",
      "Epoch 20: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.5946 - accuracy: 0.8001 - val_loss: 1.1481 - val_accuracy: 0.6799\n",
      "Epoch 21/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5759 - accuracy: 0.8076\n",
      "Epoch 21: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 77ms/step - loss: 0.5763 - accuracy: 0.8075 - val_loss: 1.1267 - val_accuracy: 0.6733\n",
      "Epoch 22/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5664 - accuracy: 0.8104\n",
      "Epoch 22: val_loss did not improve from 1.04348\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.5659 - accuracy: 0.8104 - val_loss: 1.2726 - val_accuracy: 0.6839\n",
      "Epoch 23/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5557 - accuracy: 0.8173\n",
      "Epoch 23: val_loss improved from 1.04348 to 1.03086, saving model to model.h5\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.5565 - accuracy: 0.8170 - val_loss: 1.0309 - val_accuracy: 0.7025\n",
      "Epoch 24/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5006 - accuracy: 0.8297\n",
      "Epoch 24: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.5005 - accuracy: 0.8300 - val_loss: 1.1813 - val_accuracy: 0.6783\n",
      "Epoch 25/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4859 - accuracy: 0.8388\n",
      "Epoch 25: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4868 - accuracy: 0.8385 - val_loss: 1.1716 - val_accuracy: 0.6945\n",
      "Epoch 26/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.5012 - accuracy: 0.8336\n",
      "Epoch 26: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.5008 - accuracy: 0.8337 - val_loss: 1.1451 - val_accuracy: 0.7031\n",
      "Epoch 27/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4705 - accuracy: 0.8423\n",
      "Epoch 27: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4704 - accuracy: 0.8423 - val_loss: 1.2702 - val_accuracy: 0.6955\n",
      "Epoch 28/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4583 - accuracy: 0.8460\n",
      "Epoch 28: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4588 - accuracy: 0.8459 - val_loss: 1.1674 - val_accuracy: 0.7117\n",
      "Epoch 29/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4429 - accuracy: 0.8519\n",
      "Epoch 29: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4430 - accuracy: 0.8520 - val_loss: 1.2219 - val_accuracy: 0.6928\n",
      "Epoch 30/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4307 - accuracy: 0.8567\n",
      "Epoch 30: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4306 - accuracy: 0.8566 - val_loss: 1.1995 - val_accuracy: 0.6899\n",
      "Epoch 31/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4391 - accuracy: 0.8505\n",
      "Epoch 31: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4396 - accuracy: 0.8504 - val_loss: 1.2499 - val_accuracy: 0.6796\n",
      "Epoch 32/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4103 - accuracy: 0.8607\n",
      "Epoch 32: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4099 - accuracy: 0.8608 - val_loss: 1.2011 - val_accuracy: 0.6912\n",
      "Epoch 33/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4333 - accuracy: 0.8564\n",
      "Epoch 33: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4331 - accuracy: 0.8566 - val_loss: 1.2471 - val_accuracy: 0.6902\n",
      "Epoch 34/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8619\n",
      "Epoch 34: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.4101 - accuracy: 0.8621 - val_loss: 1.3069 - val_accuracy: 0.6849\n",
      "Epoch 35/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8776\n",
      "Epoch 35: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.3711 - accuracy: 0.8776 - val_loss: 1.2438 - val_accuracy: 0.7094\n",
      "Epoch 36/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3738 - accuracy: 0.8732\n",
      "Epoch 36: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.3742 - accuracy: 0.8731 - val_loss: 1.2095 - val_accuracy: 0.7114\n",
      "Epoch 37/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3742 - accuracy: 0.8754\n",
      "Epoch 37: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.3743 - accuracy: 0.8754 - val_loss: 1.4794 - val_accuracy: 0.6928\n",
      "Epoch 38/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3756 - accuracy: 0.8743\n",
      "Epoch 38: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.3756 - accuracy: 0.8743 - val_loss: 1.3387 - val_accuracy: 0.6948\n",
      "Epoch 39/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3530 - accuracy: 0.8819\n",
      "Epoch 39: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.3530 - accuracy: 0.8817 - val_loss: 1.3336 - val_accuracy: 0.7078\n",
      "Epoch 40/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 0.3480 - accuracy: 0.8814\n",
      "Epoch 40: val_loss did not improve from 1.03086\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 0.3482 - accuracy: 0.8814 - val_loss: 1.3986 - val_accuracy: 0.6892\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train = np.load(\"X_train.npy\") \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "print(np.sum(y_train, axis=0))\n",
    "\n",
    "X_val = np.load(\"X_val.npy\")\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))\n",
    "y_val = np.load(\"y_val.npy\")\n",
    "\n",
    "print(np.sum(y_val, axis=0))\n",
    "\n",
    "model = create_model(batch_normalization)\n",
    "model = train_model(model, X_train, X_val, y_train, y_val, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
