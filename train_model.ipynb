{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Dense, Conv2D, \\\n",
    "        MaxPooling2D, GlobalMaxPooling2D, Dropout, LeakyReLU, ZeroPadding2D\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set if batch normalization is needed for training the CNN\n",
    "batch_normalization = True\n",
    "epochs = 40\n",
    "\n",
    "def create_model(batch_norm):\n",
    "    \"\"\"Creates the CNN model\n",
    "\n",
    "    Args:\n",
    "        batch_norm (bool): decides whether to batch normalize the conv layers\n",
    "\n",
    "    Returns:\n",
    "        model (Sequential): CNN model\n",
    "    \"\"\"\n",
    "    # If batch normalization, bias can be ignored\n",
    "    use_bias=True\n",
    "    if batch_norm:\n",
    "        use_bias=False\n",
    "    model = Sequential()\n",
    "\n",
    "    # Conv layer 1: 3x3 convolution layer and 32 filters,\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), input_shape=(128, 43, 1),\n",
    "        data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv layer 1: 3x3 convolution layer and 32 filters,\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), data_format=\"channels_last\"))\n",
    "\n",
    "    # dropout\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Conv Layer 3: 3x3 convolution layer and 64 filters,\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv layer 4: 3x3 convolution layer and 64 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), data_format=\"channels_last\"))\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Conv layer 5: 3x3 convolution layer and 128 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format = 'channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv layer 6: 3x3 convolution layer and 128 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), data_format=\"channels_last\"))\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    # Conv layer 7: 3x3 convolution layer and 256 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Conv block 8: 3x3 convolution layer and 256 filters\n",
    "    model.add(ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=(1, 1), padding='same', use_bias=use_bias,\n",
    "        data_format='channels_last'))\n",
    "    model.add(LeakyReLU(alpha=0.33))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # Global max-pool layer\n",
    "    model.add(GlobalMaxPooling2D(data_format=\"channels_last\"))\n",
    "\n",
    "    # Dense layer\n",
    "    model.add(Dense(1024, use_bias=use_bias))\n",
    "    if batch_norm: model.add(BatchNormalization())\n",
    "\n",
    "    # dropout layer\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(11, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    optimizer = Adam(0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,  X_train, X_val, y_train, y_val, epochs=20):\n",
    "    \"\"\"Train the CNN model\n",
    "    \"\"\"\n",
    "    tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                                      write_graph=True, write_images=False)\n",
    "    checkpoint = ModelCheckpoint('model.h5', \n",
    "            verbose=1, monitor='val_loss',save_best_only=True, mode='auto') \n",
    "    callbacks = [tensorboard, checkpoint]\n",
    "    \n",
    "    history = model.fit(x=X_train, y=y_train, batch_size=128, epochs=epochs,\n",
    "            validation_data=(X_val, y_val), callbacks=callbacks, shuffle=True)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 978. 1290. 1176. 1635. 1914. 1728. 1827. 1644. 1458. 1494. 1953.]\n",
      "[186. 225. 177. 276. 366. 318. 336. 234. 273. 246. 381.]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " zero_padding2d (ZeroPaddin  (None, 130, 45, 1)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 130, 45, 32)       288       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 130, 45, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 130, 45, 32)       128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " zero_padding2d_1 (ZeroPadd  (None, 132, 47, 32)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 132, 47, 32)       9216      \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 132, 47, 32)       0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 132, 47, 32)       128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 44, 15, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 44, 15, 32)        0         \n",
      "                                                                 \n",
      " zero_padding2d_2 (ZeroPadd  (None, 46, 17, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 17, 64)        18432     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 46, 17, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 46, 17, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " zero_padding2d_3 (ZeroPadd  (None, 48, 19, 64)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 48, 19, 64)        36864     \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 48, 19, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 48, 19, 64)        256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 16, 6, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 6, 64)         0         \n",
      "                                                                 \n",
      " zero_padding2d_4 (ZeroPadd  (None, 18, 8, 64)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 18, 8, 128)        73728     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 18, 8, 128)        0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 18, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " zero_padding2d_5 (ZeroPadd  (None, 20, 10, 128)       0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 20, 10, 128)       147456    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 20, 10, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 20, 10, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 6, 3, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 3, 128)         0         \n",
      "                                                                 \n",
      " zero_padding2d_6 (ZeroPadd  (None, 8, 5, 128)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 5, 256)         294912    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 8, 5, 256)         0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 8, 5, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " zero_padding2d_7 (ZeroPadd  (None, 10, 7, 256)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 10, 7, 256)        589824    \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 10, 7, 256)        0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 10, 7, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 256)               0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              262144    \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 1024)              4096      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 11)                11275     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1452075 (5.54 MB)\n",
      "Trainable params: 1448107 (5.52 MB)\n",
      "Non-trainable params: 3968 (15.50 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 13:17:33.295982: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 2.6093 - accuracy: 0.2416\n",
      "Epoch 1: val_loss improved from inf to 3.66932, saving model to model.h5\n",
      "134/134 [==============================] - 37s 115ms/step - loss: 2.6093 - accuracy: 0.2416 - val_loss: 3.6693 - val_accuracy: 0.1127\n",
      "Epoch 2/40\n",
      "  1/134 [..............................] - ETA: 7s - loss: 2.4740 - accuracy: 0.2969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhijith/anaconda3/envs/vt/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/134 [============================>.] - ETA: 0s - loss: 2.0195 - accuracy: 0.3803\n",
      "Epoch 2: val_loss did not improve from 3.66932\n",
      "134/134 [==============================] - 9s 65ms/step - loss: 2.0191 - accuracy: 0.3804 - val_loss: 9.5008 - val_accuracy: 0.1113\n",
      "Epoch 3/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.7336 - accuracy: 0.4648\n",
      "Epoch 3: val_loss did not improve from 3.66932\n",
      "134/134 [==============================] - 9s 71ms/step - loss: 1.7339 - accuracy: 0.4644 - val_loss: 7.4619 - val_accuracy: 0.1256\n",
      "Epoch 4/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.5383 - accuracy: 0.5212\n",
      "Epoch 4: val_loss did not improve from 3.66932\n",
      "134/134 [==============================] - 10s 76ms/step - loss: 1.5371 - accuracy: 0.5214 - val_loss: 3.7140 - val_accuracy: 0.2744\n",
      "Epoch 5/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4220 - accuracy: 0.5573\n",
      "Epoch 5: val_loss improved from 3.66932 to 1.73171, saving model to model.h5\n",
      "134/134 [==============================] - 11s 84ms/step - loss: 1.4220 - accuracy: 0.5573 - val_loss: 1.7317 - val_accuracy: 0.4960\n",
      "Epoch 6/40\n",
      "133/134 [============================>.] - ETA: 0s - loss: 1.3061 - accuracy: 0.5908\n",
      "Epoch 6: val_loss improved from 1.73171 to 1.62679, saving model to model.h5\n",
      "134/134 [==============================] - 12s 87ms/step - loss: 1.3057 - accuracy: 0.5907 - val_loss: 1.6268 - val_accuracy: 0.5195\n",
      "Epoch 7/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.2225 - accuracy: 0.6109\n",
      "Epoch 7: val_loss improved from 1.62679 to 1.51405, saving model to model.h5\n",
      "134/134 [==============================] - 13s 96ms/step - loss: 1.2225 - accuracy: 0.6109 - val_loss: 1.5140 - val_accuracy: 0.5948\n",
      "Epoch 8/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1535 - accuracy: 0.6306\n",
      "Epoch 8: val_loss improved from 1.51405 to 1.25913, saving model to model.h5\n",
      "134/134 [==============================] - 13s 97ms/step - loss: 1.1535 - accuracy: 0.6306 - val_loss: 1.2591 - val_accuracy: 0.6166\n",
      "Epoch 9/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.6550\n",
      "Epoch 9: val_loss did not improve from 1.25913\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 1.0777 - accuracy: 0.6550 - val_loss: 1.2717 - val_accuracy: 0.6064\n",
      "Epoch 10/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.0168 - accuracy: 0.6692\n",
      "Epoch 10: val_loss improved from 1.25913 to 1.07501, saving model to model.h5\n",
      "134/134 [==============================] - 14s 101ms/step - loss: 1.0168 - accuracy: 0.6692 - val_loss: 1.0750 - val_accuracy: 0.6587\n",
      "Epoch 11/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9660 - accuracy: 0.6856\n",
      "Epoch 11: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 0.9660 - accuracy: 0.6856 - val_loss: 1.1581 - val_accuracy: 0.6567\n",
      "Epoch 12/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8956 - accuracy: 0.7060\n",
      "Epoch 12: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 13s 100ms/step - loss: 0.8956 - accuracy: 0.7060 - val_loss: 1.4639 - val_accuracy: 0.5802\n",
      "Epoch 13/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8500 - accuracy: 0.7205\n",
      "Epoch 13: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 14s 102ms/step - loss: 0.8500 - accuracy: 0.7205 - val_loss: 1.4427 - val_accuracy: 0.6213\n",
      "Epoch 14/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8138 - accuracy: 0.7319\n",
      "Epoch 14: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 14s 106ms/step - loss: 0.8138 - accuracy: 0.7319 - val_loss: 1.2304 - val_accuracy: 0.6448\n",
      "Epoch 15/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.7681 - accuracy: 0.7463\n",
      "Epoch 15: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 15s 109ms/step - loss: 0.7681 - accuracy: 0.7463 - val_loss: 1.3064 - val_accuracy: 0.6100\n",
      "Epoch 16/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.7278 - accuracy: 0.7590\n",
      "Epoch 16: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 0.7278 - accuracy: 0.7590 - val_loss: 1.1734 - val_accuracy: 0.6484\n",
      "Epoch 17/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6954 - accuracy: 0.7681\n",
      "Epoch 17: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 15s 112ms/step - loss: 0.6954 - accuracy: 0.7681 - val_loss: 1.4373 - val_accuracy: 0.6173\n",
      "Epoch 18/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.7767\n",
      "Epoch 18: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 15s 113ms/step - loss: 0.6642 - accuracy: 0.7767 - val_loss: 1.6809 - val_accuracy: 0.5825\n",
      "Epoch 19/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.7900\n",
      "Epoch 19: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 15s 115ms/step - loss: 0.6247 - accuracy: 0.7900 - val_loss: 1.1829 - val_accuracy: 0.6789\n",
      "Epoch 20/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5815 - accuracy: 0.8039\n",
      "Epoch 20: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 16s 117ms/step - loss: 0.5815 - accuracy: 0.8039 - val_loss: 1.1354 - val_accuracy: 0.6769\n",
      "Epoch 21/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8138\n",
      "Epoch 21: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 16s 121ms/step - loss: 0.5495 - accuracy: 0.8138 - val_loss: 1.0806 - val_accuracy: 0.7001\n",
      "Epoch 22/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.8208\n",
      "Epoch 22: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 16s 117ms/step - loss: 0.5309 - accuracy: 0.8208 - val_loss: 1.2578 - val_accuracy: 0.6706\n",
      "Epoch 23/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4997 - accuracy: 0.8293\n",
      "Epoch 23: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 16s 118ms/step - loss: 0.4997 - accuracy: 0.8293 - val_loss: 1.2677 - val_accuracy: 0.6750\n",
      "Epoch 24/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.8457\n",
      "Epoch 24: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 16s 120ms/step - loss: 0.4629 - accuracy: 0.8457 - val_loss: 1.2039 - val_accuracy: 0.7041\n",
      "Epoch 25/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4632 - accuracy: 0.8447\n",
      "Epoch 25: val_loss did not improve from 1.07501\n",
      "134/134 [==============================] - 16s 121ms/step - loss: 0.4632 - accuracy: 0.8447 - val_loss: 1.2162 - val_accuracy: 0.6889\n",
      "Epoch 26/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.8565\n",
      "Epoch 26: val_loss improved from 1.07501 to 0.95442, saving model to model.h5\n",
      "134/134 [==============================] - 16s 122ms/step - loss: 0.4278 - accuracy: 0.8565 - val_loss: 0.9544 - val_accuracy: 0.7478\n",
      "Epoch 27/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.8688\n",
      "Epoch 27: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 125ms/step - loss: 0.3865 - accuracy: 0.8688 - val_loss: 1.1209 - val_accuracy: 0.6965\n",
      "Epoch 28/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3953 - accuracy: 0.8655\n",
      "Epoch 28: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 125ms/step - loss: 0.3953 - accuracy: 0.8655 - val_loss: 1.3119 - val_accuracy: 0.6981\n",
      "Epoch 29/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.8814\n",
      "Epoch 29: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 125ms/step - loss: 0.3464 - accuracy: 0.8814 - val_loss: 1.3808 - val_accuracy: 0.6759\n",
      "Epoch 30/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3522 - accuracy: 0.8792\n",
      "Epoch 30: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 125ms/step - loss: 0.3522 - accuracy: 0.8792 - val_loss: 1.1220 - val_accuracy: 0.7362\n",
      "Epoch 31/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3197 - accuracy: 0.8881\n",
      "Epoch 31: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 129ms/step - loss: 0.3197 - accuracy: 0.8881 - val_loss: 1.0472 - val_accuracy: 0.7270\n",
      "Epoch 32/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.8903\n",
      "Epoch 32: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 124ms/step - loss: 0.3204 - accuracy: 0.8903 - val_loss: 1.1705 - val_accuracy: 0.7260\n",
      "Epoch 33/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.9014\n",
      "Epoch 33: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 126ms/step - loss: 0.2867 - accuracy: 0.9014 - val_loss: 1.5070 - val_accuracy: 0.6892\n",
      "Epoch 34/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.9051\n",
      "Epoch 34: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 126ms/step - loss: 0.2825 - accuracy: 0.9051 - val_loss: 1.3780 - val_accuracy: 0.7140\n",
      "Epoch 35/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.9084\n",
      "Epoch 35: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 128ms/step - loss: 0.2756 - accuracy: 0.9084 - val_loss: 1.1746 - val_accuracy: 0.7469\n",
      "Epoch 36/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2648 - accuracy: 0.9079\n",
      "Epoch 36: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 127ms/step - loss: 0.2648 - accuracy: 0.9079 - val_loss: 1.2079 - val_accuracy: 0.7200\n",
      "Epoch 37/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9226\n",
      "Epoch 37: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 127ms/step - loss: 0.2274 - accuracy: 0.9226 - val_loss: 1.2931 - val_accuracy: 0.7240\n",
      "Epoch 38/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.9126\n",
      "Epoch 38: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 127ms/step - loss: 0.2468 - accuracy: 0.9126 - val_loss: 1.4976 - val_accuracy: 0.6756\n",
      "Epoch 39/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9224\n",
      "Epoch 39: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 127ms/step - loss: 0.2258 - accuracy: 0.9224 - val_loss: 1.3716 - val_accuracy: 0.7409\n",
      "Epoch 40/40\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9213\n",
      "Epoch 40: val_loss did not improve from 0.95442\n",
      "134/134 [==============================] - 17s 129ms/step - loss: 0.2318 - accuracy: 0.9213 - val_loss: 1.2526 - val_accuracy: 0.7319\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = np.load(\"X_train.npy\") \n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "print(np.sum(y_train, axis=0))\n",
    "\n",
    "X_val = np.load(\"X_val.npy\")\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))\n",
    "y_val = np.load(\"y_val.npy\")\n",
    "\n",
    "print(np.sum(y_val, axis=0))\n",
    "\n",
    "model = create_model(batch_normalization)\n",
    "model = train_model(model, X_train, X_val, y_train, y_val, epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
